{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%cd ./../",
   "id": "d52fcfb1bc3e8af4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['INDEX'] = str(0)\n",
    "\n",
    "# TODO: share the code with the `logs.py` file.\n",
    "\n",
    "logging.basicConfig(\n",
    "\tformat=\"{name}\\t{asctime}\\t{levelname}\\t{message}\\t\",\n",
    "\tstyle='{',\n",
    "\tlevel=logging.DEBUG\n",
    ")\n",
    "logging.getLogger('PIL.PngImagePlugin').disabled = True\n",
    "logging.getLogger('matplotlib').disabled = True\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True"
   ],
   "id": "b6704e558623d925",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import repro  # Imported for its side effects.",
   "id": "772652a5147c6b5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# noinspection PyUnresolvedReferences\n",
    "from data import train_data_loader, test_data_loader, train_eval_data_loader\n",
    "from model import model\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import optim\n",
    "from finetunes.lr import MyLrFinder as LRFinder\n",
    "\n",
    "criterion = CrossEntropyLoss()  # TODO: move into a module to share with the `main` module.\n",
    "optimizer = optim.init()\n",
    "\n",
    "lr_finder = LRFinder(model=model, optimizer=optimizer, criterion=criterion)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import conf\n",
    "\n",
    "try:\n",
    "\tlr_finder.range_test(\n",
    "\t\ttrain_loader=train_data_loader,\n",
    "\t\t# val_loader=train_eval_data_loader,\n",
    "\t\t# val_loader=test_data_loader, # Data leakage warning!\n",
    "\t\tstart_lr=1e-7, end_lr=0.5,\n",
    "\t\tnum_iter=len(train_data_loader) * conf.EPOCHS * 1,\n",
    "\t\t# num_iter=conf.ROUNDS, epochs_per_iter=conf.EPOCHS,\n",
    "\t\t# reset_per_iter=True,\n",
    "\t\tsmooth_f=0.05, diverge_th=5\n",
    "\t)\n",
    "finally:\n",
    "\tlr_finder.reset()"
   ],
   "id": "d2731d398e362a15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from finetunes.lr import find_lr_steep_grad\n",
    "import plotly.express as px\n",
    "\n",
    "df = [{'lr': lr, 'loss': loss} for lr, loss in zip(lr_finder.history['lr'], lr_finder.history['loss'])]\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "fig = px.line(\n",
    "\tdf,\n",
    "\tx='lr', y='loss', log_x=True,\n",
    "\ttitle='Loss vs. Learning Rate', labels={'lr': 'Learning Rate', 'loss': 'Loss'},\n",
    ")\n",
    "\n",
    "steep_grad_lr, steep_grad_loss = find_lr_steep_grad(lr_finder)\n",
    "fig.add_scatter(x=(steep_grad_lr,), y=(steep_grad_loss,), name='Steep. Grad.')\n",
    "\n",
    "fig.show()"
   ],
   "id": "a895259d3e8817da",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
